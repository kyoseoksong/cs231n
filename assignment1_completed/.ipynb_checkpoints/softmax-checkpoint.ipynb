{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "The intent of this ipynb is only to explain softmax loss gradient calculation. I am taking cs231 assignment code to  [cs231n assignment1](http://vision.stanford.edu/teaching/cs231n/assignments.html). \n",
    "\n",
    "In this exercise you will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈을 import 하고 파라미터 설정을 해 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 데이터를 불러와서 preprocessing, normalization, bias 처리 해 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "  \"\"\"\n",
    "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "  it for the linear classifier. These are the same steps as we used for the\n",
    "  SVM, but condensed to a single function.  \n",
    "  \"\"\"\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir) # (50000,32,32,3) (50000) (10000,32,32,3) (10000)\n",
    "  \n",
    "  # subsample the data\n",
    "    \n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask] # (1000,32,32,3)\n",
    "  y_val = y_train[mask] # (1000,)\n",
    "  \n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask] # (49000, 32, 32, 3)\n",
    "  y_train = y_train[mask] # (49000,)\n",
    "  \n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask] # (1000, 32, 32, 3)\n",
    "  y_test = y_test[mask] # (1000,)\n",
    "\n",
    "  mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "  X_dev = X_train[mask] # (500,32,32,3)\n",
    "  y_dev = y_train[mask] # (500,)\n",
    "  \n",
    "  # Preprocessing: reshape the image data into rows\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], -1)) # (49000, 3072)\n",
    "  X_val = np.reshape(X_val, (X_val.shape[0], -1)) # (1000, 3072)\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], -1)) # (1000, 3072)\n",
    "  X_dev = np.reshape(X_dev, (X_dev.shape[0], -1)) # (500, 3072)\n",
    "  \n",
    "  # Normalize the data: subtract the mean image\n",
    "  mean_image = np.mean(X_train, axis = 0) # (3072,)\n",
    "  X_train -= mean_image # (49000,3072) - (3072,) = (49000,3072)\n",
    "  X_val -= mean_image # (1000,3072) - (3072,) = (1000,3072)\n",
    "  X_test -= mean_image # (1000,3072) - (3072,) = (1000,3072)\n",
    "  X_dev -= mean_image # (500,3072) - (3072,) = (500,3072)\n",
    "  \n",
    "  # add bias dimension and transform into columns\n",
    "  X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]) # (49000, 3073) # X_train[0][3072] = 1.0\n",
    "  X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]) # (1000, 3073)\n",
    "  X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]) # (1000, 3073)\n",
    "  X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))]) # (500, 3073)\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape\n",
    "print 'dev data shape: ', X_dev.shape\n",
    "print 'dev labels shape: ', y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax gradient calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sofmax score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After multiplying input matrix X with weights matrix W we get class scores. Then we apply softmax function over it. Sofmax score function $p(z)$ takes a vector of arbitrary real-valued scores (e.g. predicted scores $z[]$) and squashes it to a vector of values between zero and one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p_j(z) = \\frac { e^{z_j} } { \\sum_k {e^{z_k}} }  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98670329  0.00664835  0.00664835]]\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.softmax import softmax\n",
    "z = np.array([10.0,5.0,5.0])\n",
    "p = softmax(z)\n",
    "print p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-entropy between a \"true\" distribution $p$ and an estimated distribution $q$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(p,q) = -\\sum_x p(x) log( q(x) ) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Softmax classifier is hence minimizing the cross-entropy between the estimated class probabilities $p(z)$ and the \"true\" distribution, which in this interpretation is the distribution where all probability mass is on the correct class (i.e. p=[0,…1,…,0]p=[0,…1,…,0] contains a single 1 at the $yi$-th position.). For simplicity, let's consider $Y$ as one-hot encoded labels for $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_i = -\\sum_j Y_j log( \\frac { e^{f_{j}} } { \\sum_k {e^{f_k}} } )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y_j$ is zero except at position $y_i$ which represents true class label for $i$-th training input. So, our loss equation simplifies to: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_i = -log( \\frac { e^{f_{y_i}} } { \\sum_k {e^{f_k}} } )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifying further..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_i = -f_{y_i} + log(\\sum_k {e^{f_k}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_i = -w_{y_i}x_i + log(\\sum_k {e^{w_k x_i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\delta L_i}{\\delta w_j} = -\\frac{\\delta w_{y_i}} {\\delta w_j} x_i + \\frac {1} {\\sum_k {e^{w_k x_i}}} \\frac{\\delta \\sum_k e^{w_k x_i}}{\\delta w_j} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $\\frac{\\delta e^{w_k}}{\\delta w_j} = 0 $; except when $k == j$. Applying chain rule leads to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\delta L_i}{\\delta w_j} = -\\frac{\\delta w_{y_i}} {\\delta w_j} x_i + \\frac {e^{w_j x_i}} {\\sum_k {e^{w_k x_i}}} x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term $\\frac {e^{w_j x_i}} {\\sum_k {e^{w_k x_i}}}$ is the softmax score for the class j which we already computed i.e. $p_j(z)$. In other words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\delta L_i}{\\delta w_j} = -\\frac{\\delta w_{y_i}} {\\delta w_j} x_i + f_j x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "j == y_i \\implies \\frac{\\delta w_{y_i}} {\\delta w_j} = 1 \\\\\n",
    "j \\not= y_i \\implies \\frac{\\delta w_{y_i}} {\\delta w_j} = 0  \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our final gradient update becomes:\n",
    "~~~python \n",
    "dW[:,j] += (p[j] - (j==y[i]))*X[i,:] \n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization 하고 softmax_loss_naive 함수를 이용해 초기의 Loss 구하고 sanity check\n",
    "아직은 training data가 아니라 development data를 이용해서 실제로 softmax를 이용한 loss 구하고 sanity check 하는 단계이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.379882\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print 'loss: %f' % loss\n",
    "print 'sanity check: %f' % (-np.log(0.1)) # loss == log(# of classes) 2개의 결과가 거의 같아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *There are 10 classes, so with random weights we expect to get correct output with the probability of 0.1. We accumulate negative log loss of the incorrect class probability score, i.e., -log(0.1)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다시 한번 softmax_loss_naive 함수를 이용해 loss와 gradient를 구한 다음에 gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.243242 analytic: -0.243242, relative error: 6.020941e-08\n",
      "numerical: 1.135368 analytic: 1.135368, relative error: 1.927766e-08\n",
      "numerical: 0.782196 analytic: 0.782196, relative error: 8.894593e-08\n",
      "numerical: 2.635231 analytic: 2.635231, relative error: 1.760806e-08\n",
      "numerical: 2.153963 analytic: 2.153963, relative error: 2.627008e-08\n",
      "numerical: -6.592937 analytic: -6.592937, relative error: 2.761366e-09\n",
      "numerical: -2.561547 analytic: -2.561547, relative error: 6.375837e-09\n",
      "numerical: 2.363981 analytic: 2.363981, relative error: 2.039156e-08\n",
      "numerical: 1.365571 analytic: 1.365571, relative error: 2.727372e-08\n",
      "numerical: 2.970437 analytic: 2.970437, relative error: 4.169584e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번에는 regularization 까지 포함된 loss와 gradient를 구한 다음에 gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 1.752811 analytic: 1.752811, relative error: 5.190023e-09\n",
      "numerical: 4.374247 analytic: 4.374247, relative error: 1.535986e-08\n",
      "numerical: -0.765966 analytic: -0.765966, relative error: 2.039100e-08\n",
      "numerical: 4.116887 analytic: 4.116887, relative error: 1.626840e-08\n",
      "numerical: -1.292958 analytic: -1.292958, relative error: 3.570521e-08\n",
      "numerical: -3.165935 analytic: -3.165935, relative error: 1.037555e-09\n",
      "numerical: 1.892414 analytic: 1.892414, relative error: 1.744858e-08\n",
      "numerical: 0.026034 analytic: 0.026034, relative error: 3.079252e-06\n",
      "numerical: -0.159509 analytic: -0.159509, relative error: 4.401772e-07\n",
      "numerical: 1.065854 analytic: 1.065853, relative error: 6.634249e-08\n"
     ]
    }
   ],
   "source": [
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax_loss_naive 와 softmax_loss_vectorized 비교 - 소요시간과 loss, gradient 차이 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.379882e+00 computed in 0.182193s\n",
      "vectorized loss: 2.379882e+00 computed in 0.010686s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'naive loss: %e computed in %fs' % (loss_naive, toc - tic)\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro') # grad는 matrix 이므로 이렇게 비교\n",
    "print 'Loss difference: %f' % np.abs(loss_naive - loss_vectorized) # loss 는 scalar 이므로 이렇게 비교\n",
    "print 'Gradient difference: %f' % grad_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set을 이용해서 Hyperparameter (regularization과 learning rate) 를 튜닝한다\n",
    "\n",
    "이제 최적의 regularization과 learning rate를 찾기 위해 실제로 training data를 이용해 training accuracy와 validation accuracy를 구해 본다.\n",
    "\n",
    "(test accuracy는 아직이다)\n",
    "\n",
    "각각 다른 learning rate와 regularization에 대해 다음 작업을 300회만 반복한다.\n",
    "* 실제 training data를 이용해 학습시키면서 loss를 구한다.\n",
    "* training accuracy와 validation accuracy를 구한다\n",
    "\n",
    "이를 통해 validation accuracy가 가장 높은 learning rate와 regularization을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning rate =  1e-07 reg =  50000.0\n",
      "iteration 0 / 300: loss 765.558453\n",
      "iteration 100 / 300: loss 280.906751\n",
      "iteration 200 / 300: loss 103.913962\n",
      "\n",
      "learning rate =  1e-07 reg =  100000000.0\n",
      "iteration 0 / 300: loss 1547605.415269\n",
      "iteration 100 / 300: loss inf\n",
      "iteration 200 / 300: loss inf\n",
      "\n",
      "learning rate =  5e-07 reg =  50000.0\n",
      "iteration 0 / 300: loss 777.491221\n",
      "iteration 100 / 300: loss 6.888827\n",
      "iteration 200 / 300: loss 2.100422\n",
      "\n",
      "learning rate =  5e-07 reg =  100000000.0\n",
      "iteration 0 / 300: loss 1550226.222147\n",
      "iteration 100 / 300: loss inf\n",
      "iteration 200 / 300: loss nan\n",
      "\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.244959 val accuracy: 0.239000\n",
      "lr 1.000000e-07 reg 1.000000e+08 train accuracy: 0.129082 val accuracy: 0.115000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.319061 val accuracy: 0.334000\n",
      "lr 5.000000e-07 reg 1.000000e+08 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "\n",
      "best validation accuracy achieved during cross-validation: 0.334000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax # 대문자임에 유의! linear_classifier.py\n",
    "\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [5e4, 1e8]\n",
    "\n",
    "results = {} # key는 (learning_rate, reg), value는 (train_accuracy, valid_accuracy)\n",
    "\n",
    "best_val = -1 # best validation accuracy 저장\n",
    "best_softmax = None # best softmax 모델 저장\n",
    "best_learning_rate = None # best learning rate 저장\n",
    "best_reg  = None # best regularization 저장\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for learning_rate in learning_rates: # 2 loops [1e-7, 5e-7]\n",
    "     for reg in regularization_strengths: # 2 loops [5e4, 1e8] \n",
    "        print\n",
    "        print \"learning rate = \", learning_rate, \"reg = \", reg\n",
    "        softmax_ = Softmax()\n",
    "        loss = softmax_.train(X_train, y_train, learning_rate=learning_rate, reg=reg,\n",
    "                      num_iters=300, verbose=True) # loss는 300개의 loss_history 를 담은 list # len(loss) = 300\n",
    "\n",
    "        y_train_pred = softmax_.predict(X_train) # (49000,)\n",
    "        train_accuracy = (np.mean(y_train == y_train_pred))\n",
    "        \n",
    "        y_val_pred = softmax_.predict(X_val) # (1000,)\n",
    "        valid_accuracy = (np.mean(y_val == y_val_pred))\n",
    "        \n",
    "        results[(learning_rate, reg)] = (train_accuracy, valid_accuracy)\n",
    "        \n",
    "        if best_val == -1 or valid_accuracy > best_val:\n",
    "            best_val = valid_accuracy\n",
    "            best_softmax = softmax_\n",
    "            best_learning_rate = learning_rate\n",
    "            best_reg = reg\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "print\n",
    "for lr, reg in sorted(results): # sorting의 기준은 lr, reg 순서???\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy)\n",
    "    \n",
    "print\n",
    "print 'best validation accuracy achieved during cross-validation: %f' % best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위에서 구한 최적의 regularization과 learning rate 를 이용해 본격적으로 학습시킨다\n",
    "\n",
    "10,000회 학습을 통해 loss를 최소화하는 모델을 도출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 10000: loss 764.759297\n",
      "iteration 100 / 10000: loss 6.880296\n",
      "iteration 200 / 10000: loss 2.139003\n",
      "iteration 300 / 10000: loss 2.131524\n",
      "iteration 400 / 10000: loss 2.097775\n",
      "iteration 500 / 10000: loss 2.038996\n",
      "iteration 600 / 10000: loss 2.071935\n",
      "iteration 700 / 10000: loss 2.138959\n",
      "iteration 800 / 10000: loss 2.030946\n",
      "iteration 900 / 10000: loss 2.046500\n",
      "iteration 1000 / 10000: loss 2.081396\n",
      "iteration 1100 / 10000: loss 2.107182\n",
      "iteration 1200 / 10000: loss 2.059976\n",
      "iteration 1300 / 10000: loss 2.107473\n",
      "iteration 1400 / 10000: loss 2.157871\n",
      "iteration 1500 / 10000: loss 2.098482\n",
      "iteration 1600 / 10000: loss 2.078595\n",
      "iteration 1700 / 10000: loss 2.085505\n",
      "iteration 1800 / 10000: loss 2.059444\n",
      "iteration 1900 / 10000: loss 2.077128\n",
      "iteration 2000 / 10000: loss 2.122319\n",
      "iteration 2100 / 10000: loss 2.122413\n",
      "iteration 2200 / 10000: loss 2.105511\n",
      "iteration 2300 / 10000: loss 2.112488\n",
      "iteration 2400 / 10000: loss 2.085627\n",
      "iteration 2500 / 10000: loss 2.149098\n",
      "iteration 2600 / 10000: loss 2.129700\n",
      "iteration 2700 / 10000: loss 2.085167\n",
      "iteration 2800 / 10000: loss 2.163592\n",
      "iteration 2900 / 10000: loss 2.124430\n",
      "iteration 3000 / 10000: loss 2.048164\n",
      "iteration 3100 / 10000: loss 2.111972\n",
      "iteration 3200 / 10000: loss 2.092483\n",
      "iteration 3300 / 10000: loss 2.081841\n",
      "iteration 3400 / 10000: loss 2.089101\n",
      "iteration 3500 / 10000: loss 2.078521\n",
      "iteration 3600 / 10000: loss 2.087432\n",
      "iteration 3700 / 10000: loss 2.117639\n",
      "iteration 3800 / 10000: loss 2.092078\n",
      "iteration 3900 / 10000: loss 2.138634\n",
      "iteration 4000 / 10000: loss 2.049261\n",
      "iteration 4100 / 10000: loss 2.067469\n",
      "iteration 4200 / 10000: loss 2.062740\n",
      "iteration 4300 / 10000: loss 2.085558\n",
      "iteration 4400 / 10000: loss 2.144844\n",
      "iteration 4500 / 10000: loss 2.086939\n",
      "iteration 4600 / 10000: loss 2.127162\n",
      "iteration 4700 / 10000: loss 2.132959\n",
      "iteration 4800 / 10000: loss 2.121298\n",
      "iteration 4900 / 10000: loss 2.067773\n",
      "iteration 5000 / 10000: loss 2.145855\n",
      "iteration 5100 / 10000: loss 2.030700\n",
      "iteration 5200 / 10000: loss 2.092919\n",
      "iteration 5300 / 10000: loss 2.097032\n",
      "iteration 5400 / 10000: loss 2.071731\n",
      "iteration 5500 / 10000: loss 2.122296\n",
      "iteration 5600 / 10000: loss 2.077141\n",
      "iteration 5700 / 10000: loss 2.071173\n",
      "iteration 5800 / 10000: loss 2.092144\n",
      "iteration 5900 / 10000: loss 2.119524\n",
      "iteration 6000 / 10000: loss 2.101617\n",
      "iteration 6100 / 10000: loss 2.093926\n",
      "iteration 6200 / 10000: loss 2.135263\n",
      "iteration 6300 / 10000: loss 2.084204\n",
      "iteration 6400 / 10000: loss 2.082708\n",
      "iteration 6500 / 10000: loss 2.153930\n",
      "iteration 6600 / 10000: loss 2.088976\n",
      "iteration 6700 / 10000: loss 2.092880\n",
      "iteration 6800 / 10000: loss 2.135230\n",
      "iteration 6900 / 10000: loss 2.047145\n",
      "iteration 7000 / 10000: loss 2.132084\n",
      "iteration 7100 / 10000: loss 2.082819\n",
      "iteration 7200 / 10000: loss 2.044328\n",
      "iteration 7300 / 10000: loss 2.126612\n",
      "iteration 7400 / 10000: loss 2.039425\n",
      "iteration 7500 / 10000: loss 2.071010\n",
      "iteration 7600 / 10000: loss 2.093400\n",
      "iteration 7700 / 10000: loss 2.104262\n",
      "iteration 7800 / 10000: loss 2.098520\n",
      "iteration 7900 / 10000: loss 2.077631\n",
      "iteration 8000 / 10000: loss 2.089128\n",
      "iteration 8100 / 10000: loss 2.128590\n",
      "iteration 8200 / 10000: loss 2.081543\n",
      "iteration 8300 / 10000: loss 2.137210\n",
      "iteration 8400 / 10000: loss 2.084792\n",
      "iteration 8500 / 10000: loss 2.113944\n",
      "iteration 8600 / 10000: loss 2.050767\n",
      "iteration 8700 / 10000: loss 2.112526\n",
      "iteration 8800 / 10000: loss 2.131997\n",
      "iteration 8900 / 10000: loss 2.086537\n",
      "iteration 9000 / 10000: loss 2.047462\n",
      "iteration 9100 / 10000: loss 2.130267\n",
      "iteration 9200 / 10000: loss 2.039519\n",
      "iteration 9300 / 10000: loss 2.054670\n",
      "iteration 9400 / 10000: loss 2.112971\n",
      "iteration 9500 / 10000: loss 2.072969\n",
      "iteration 9600 / 10000: loss 2.103778\n",
      "iteration 9700 / 10000: loss 2.108634\n",
      "iteration 9800 / 10000: loss 2.094612\n",
      "iteration 9900 / 10000: loss 2.045249\n"
     ]
    }
   ],
   "source": [
    "# let's train more with the best learning rate and regularization setting\n",
    "softmax_ = Softmax()\n",
    "loss = softmax_.train(X_train, y_train, learning_rate=best_learning_rate, reg=best_reg,\n",
    "                      num_iters=10000, verbose=True) # len(loss) = 10000 (loss는 list)\n",
    "best_softmax = softmax_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy를 구해 본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.333000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print 'softmax on raw pixels final test set accuracy: %f' % (test_accuracy, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각각의 클래스에 대해 학습된 weight를 시각화해 본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzQAAAIUCAYAAADMqWn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1115a3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias # (3072, 10)\n",
    "w = w.reshape(32, 32, 3, 10) # (32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w) # ex) w_min = -3.85254101895e-05, w_max = 4.39559444241e-05\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  # Normalization by Scaling Between 0 and 1 를 이용\n",
    "  # https://docs.tibco.com/pub/spotfire/7.0.0/doc/html/norm/norm_scale_between_0_and_1.htm\n",
    "  wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) # (32, 32, 3) float between 0 and 255\n",
    "  # numpy.squeeze() : Remove single-dimensional entries from the shape of an array.\n",
    "  # https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html#numpy.squeeze\n",
    "  # 굳이 numpy.squeeze()를 쓰는 이유를 모르겠다. 아래와 같이 해도 동일한 결과가 나온다.   \n",
    "  # wimg = 255.0 * (w[:, :, :, i] - w_min) / (w_max - w_min) # (32, 32, 3) float between 0 and 255\n",
    "\n",
    "  plt.imshow(wimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
